# 配环境
conda create -n dvs_voltmeter python=3.8
conda activate dvs_voltmeter
conda install pytorch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 cudatoolkit=11.3 -c pytorch -c conda-forge
conda install easydict=1.9
conda install numpy>=1.20.1
conda install tqdm=4.49.0
conda install -c conda-forge opencv=4.5.1.48        (4090上)
pip install opencv-python       （3090Ti）
pip install pillow       （3090Ti）


！！！注意simulator_utils.py中229行修改了，用于eventnerf合成曝光数据 以后记得改回来   todo

#################################### Event3DPW_Noise,用DVS-Voltmeter ####################################
# cmd
cd D:\MyProject\DVS-Voltmeter
conda activate dvs-sim
python generate_data.py
python main.py


python data_split.py


python copy_data.py

python extract_dict.py

python generate_multidim_frame_data.py

echo finish

[3090TI]
cd E:\PythonProject\DVS-Voltmeter
conda activate EPPclone
python generate_multidim_frame_data.py

# 仿真过程
1.generate_data.py: 从源目录(E:\DVS-SIM\src\imageFiles)复制PNG图像到目标目录(E:\DVS-SIM\src\image_DVSVoltmeter)，
并生成包含每个图像路径和时间戳的info.txt文件。
2.改src/config.py里面的目录， main.py生成事件(E:/DVS-SIM/src/events/)
3.data_split.py：将事件聚合以对应标签，且按照train_val_test划分数据
4.copy_data.py:按照标签复制data(多人情况)
5.extract_dict.py：统计每个stamp的事件数，并且记录图像尺寸
6.generate_multidim_frame_data.py: 生成EF
7.Indices_to_use.npy用原来的， 复制过来

# 已经执行完的， 把ESIM的复制过来
generate_label.py：生成标签, 这步是ESIM的，替换成把label文件夹直接复制到E:\DVS-SIM\Event3DPW_Noise文件夹下
generate_rgb.py:生成与事件同尺寸的RGB图像，这步是ESIM的，替换成把rgb_data文件夹直接复制到E:\DVS-SIM\Event3DPW_Noise文件夹下
gen_test_seq.py:生成test序列名称，这步是ESIM的，替换成把seqname.txt直接复制到E:\DVS-SIM\Event3DPW_Noise文件夹下


[esim里面接下来的流程]


#################################### EventNeRF, 用DVS-Voltmeter ####################################
1.生成info.txt文件(假设总光圈变化时间为0.25s，仿真步数为100， fps为 100/0.25=400)
python generate_EventNeRF.py
2. 改src/config.py里面的目录， main.py生成事件(I:/Dataset/EventNeRF/data/nerf/chair/train/exposure_events)
cd E:\PythonProject\DVS-Voltmeter
conda activate dvs_voltmeter
python main.py

七个序列一起
python main_batch.py

3. 批量将txt存成npy文件
txt2npy_folder.py

python txt2npy_folder.py

4. 事件可视化
vis_npy
5. mp4转gif
ffmpeg -i H:\Dataset\EventNeRF\chair\train\Exposure\Ori\events.mp4 -vf "fps=30,scale=346x260:flags=lanczos" -c:v gif H:\Dataset\EventNeRF\chair\train\Exposure\Ori\output.gif
ffmpeg -i D:\研究生\博四上\组会ppt\1_5.mp4 -vf "fps=30,scale=346x260:flags=lanczos" -c:v gif D:\研究生\博四上\组会ppt\output.gif



cd E:\PythonProject\DVS-Voltmeter
conda activate dvs_voltmeter
python main_batch.py
python txt2npy_folder.py
echo finish

#################################### EventNeRF低光照, 用DVS-Voltmeter ####################################
1.生成info.txt文件(假设总光圈变化时间为为0.25s，仿真步数为100， fps为 100/0.25=400)
python generate_EventNeRF_LL.py
2. 改src/config.py里面的目录， main.py生成事件(I:/Dataset/EventNeRF/data/nerf/chair/train/Exposure/LL0.3/rgb_aperture)
cd E:\PythonProject\DVS-Voltmeter
conda activate dvs_voltmeter
python main.py

七个序列一起
python main_batch.py

3. 批量将txt存成npy文件
txt2npy_folder_LL.py


#################################### 合成’1‘视角为事件的event-ZJU-MoCap数据集,用DVS-Voltmeter ####################################
1.查看原视频fps，得到25fps
python get_fps.py
2.generate_ZJUMoCap.py: 从源目录(F:\Dataset\ZJU-MoCap_pre\CoreView_386\1)复制PNG图像到目标目录(F:\Dataset\ZJU-MoCap_pre\CoreView_386\Src_Img)，
并生成包含每个图像路径和时间戳的info.txt文件。
python generate_ZJUMoCap.py
3.改src/config.py里面的目录， main.py生成事件(F:/Dataset/ZJU-MoCap_pre/CoreView_386/events/)
cd E:\PythonProject\DVS-Voltmeter
conda activate dvs_voltmeter
python main.py
4. txt2npy.py,将txt存成npy文件




